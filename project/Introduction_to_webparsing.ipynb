{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Parsing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Web Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Parsing has 4 main steps\n",
    "\n",
    "1. Create the URL that correspond to a search or a page you want\n",
    "2. Get the content of the HTML page based on the URL\n",
    "3. Parsing the content of the HTML page to retrieve the data you want\n",
    "4. Storing / Processing this data\n",
    "\n",
    "And about these steps:\n",
    "* #1 is quite easy\n",
    "* #2 could be complex if the page is protected by password or a mechanism to prevent web scrapping\n",
    "* #3 is OK but you need to understand a bit about HTML\n",
    "* #4 is just Python stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Learning\n",
    "\n",
    "A fun and interactive way to learn has been created here:\n",
    "\n",
    "https://quizizz.com/join/lesson/621b9031fbcbe9001d6b30c2/start\n",
    "\n",
    "This refers to the two following links introducing respectively HTML and Web Parsing:\n",
    "* https://www.w3schools.com/html/html_intro.asp\n",
    "* https://medium.com/opex-analytics/simple-web-scraping-in-python-90d6fddfaeca\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of simple Web Parsing\n",
    "\n",
    "In this introduction, we will try to extract product names and prices from this website:\n",
    "http://automationpractice.com/index.php\n",
    "\n",
    "*NOTE: this is a dummy merchant website created to practice Web Test Automation and Web Scrapping.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://automationpractice.com/index.php\"\n",
    "\n",
    "# makes a request to the web page and gets its HTML\n",
    "r = requests.get(url)\n",
    "\n",
    "# stores the HTML page in 'soup', a BeautifulSoup object\n",
    "soup = BeautifulSoup(r.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show the content stored in the \"soup\" with `soup.prettify()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"a-no-js\" data-19ax5a9jf=\"dingo\" lang=\"en-gb\">\n",
      " <!-- sp:feature:head-start -->\n",
      " <head>\n",
      "  <script>\n",
      "   var aPageStart = (new Date()).getTime();\n",
      "  </script>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <!-- sp:end-feature:head-start -->\n",
      "  <script type=\"text/javascript\">\n",
      "   var ue_t0=ue_t0||+new Date();\n",
      "  </script>\n",
      "  <!-- sp:feature:cs-optimization -->\n",
      "  <meta content=\"on\" http-equiv=\"x-dns-prefetch-control\"/>\n",
      "  <link href=\"https://images-eu.ssl-images-amazon.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"https://m.media-amazon.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"https://completion.amazon.com\" rel=\"dns-prefetch\"/>\n",
      "  <!-- sp:end-feature:cs-optimization -->\n",
      "  <script type=\"text/javascript\">\n",
      "   window.ue_ihb = (window.ue_ihb || window.ueinit || 0) + 1;\n",
      "if (window.ue_ihb === 1) {\n",
      "\n",
      "var ue_csm = window,\n",
      "    ue_hob = +new Date();\n",
      "(function(d){var e=d.ue=d.ue||{},f=Date.now||function(){return+new Date};e.d=function(b){return f()-(b?0:d.ue_t0)};e.stub=function(b,a){if(!b[a]){var c=[];b[a]=f...\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing inspection of the page, we can notice that:\n",
    "* All products are in `<div clas=\"product-container\">`\n",
    "* The name of the product is (inside the product) in `<a class=\"product-name\">`\n",
    "* The price of the product is (inside the product) in `<span class=\"price product-price\">` (so searching for either class `price` or `product-price`)\n",
    "\n",
    "In BeautifulSoup, we will use:\n",
    "* `.find_all(...)` to search all products\n",
    "* `.find(...)` to search an element\n",
    "* `class_=\"...\"` to specify the class\n",
    "\n",
    "**IMPORTANT**:\n",
    "Note the underscore `_`  after \"class\" (`class_`) because `class` is a keyword used in Python language.\n",
    "\n",
    "So to get products names and prices, we could something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Faded Short Sleeve T-shirts': '$16.51',\n",
       " 'Blouse': '$27.00',\n",
       " 'Printed Dress': '$50.99',\n",
       " 'Printed Summer Dress': '$30.50',\n",
       " 'Printed Chiffon Dress': '$16.40'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_products = {}\n",
    "\n",
    "for product in soup.find_all(\"div\", class_=\"product-container\"):\n",
    "    name = product.find(\"a\", class_=\"product-name\").text.strip()\n",
    "    price = product.find(\"span\", class_=\"price\").text.strip()\n",
    "    list_products[name] = price\n",
    "\n",
    "list_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... BUT we only get 5 products because some products have the same name: so it's better to store all data in a list of Tuples for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Faded Short Sleeve T-shirts', '$16.51'),\n",
       " ('Blouse', '$27.00'),\n",
       " ('Printed Dress', '$26.00'),\n",
       " ('Printed Dress', '$50.99'),\n",
       " ('Printed Summer Dress', '$28.98'),\n",
       " ('Printed Summer Dress', '$30.50'),\n",
       " ('Printed Chiffon Dress', '$16.40'),\n",
       " ('Printed Chiffon Dress', '$16.40'),\n",
       " ('Faded Short Sleeve T-shirts', '$16.51'),\n",
       " ('Blouse', '$27.00'),\n",
       " ('Printed Summer Dress', '$28.98'),\n",
       " ('Printed Dress', '$26.00'),\n",
       " ('Printed Summer Dress', '$30.50'),\n",
       " ('Printed Dress', '$50.99')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_products_tuples = []\n",
    "\n",
    "for product in soup.find_all(\"div\", class_=\"product-container\"):\n",
    "    name = product.find(\"a\", class_=\"product-name\").text.strip()\n",
    "    price = product.find(\"span\", class_=\"price\").text.strip()\n",
    "    list_products_tuples.append((name, price))  # double parentheses here because we need a tuple\n",
    "\n",
    "list_products_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we will use `pandas`, which is THE library for data science.\n",
    "\n",
    "The data is stored in a `DataFrame`, which is the equivalent of an Excel Table.\n",
    "The usual way to create a Data Frame is:\n",
    "* from an Excel or .csv file if we have one\n",
    "* from a list of tuples, that will correspond to the values in columns\n",
    "* from a list of dictionaries, that will create the needed columns and their headers\n",
    "\n",
    "Here, we could use a list of tuples we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faded Short Sleeve T-shirts</td>\n",
       "      <td>$16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blouse</td>\n",
       "      <td>$27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Printed Dress</td>\n",
       "      <td>$26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Printed Dress</td>\n",
       "      <td>$50.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Printed Summer Dress</td>\n",
       "      <td>$28.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Printed Summer Dress</td>\n",
       "      <td>$30.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Printed Chiffon Dress</td>\n",
       "      <td>$16.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Printed Chiffon Dress</td>\n",
       "      <td>$16.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Faded Short Sleeve T-shirts</td>\n",
       "      <td>$16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blouse</td>\n",
       "      <td>$27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Printed Summer Dress</td>\n",
       "      <td>$28.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Printed Dress</td>\n",
       "      <td>$26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Printed Summer Dress</td>\n",
       "      <td>$30.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Printed Dress</td>\n",
       "      <td>$50.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Product   Price\n",
       "0   Faded Short Sleeve T-shirts  $16.51\n",
       "1                        Blouse  $27.00\n",
       "2                 Printed Dress  $26.00\n",
       "3                 Printed Dress  $50.99\n",
       "4          Printed Summer Dress  $28.98\n",
       "5          Printed Summer Dress  $30.50\n",
       "6         Printed Chiffon Dress  $16.40\n",
       "7         Printed Chiffon Dress  $16.40\n",
       "8   Faded Short Sleeve T-shirts  $16.51\n",
       "9                        Blouse  $27.00\n",
       "10         Printed Summer Dress  $28.98\n",
       "11                Printed Dress  $26.00\n",
       "12         Printed Summer Dress  $30.50\n",
       "13                Printed Dress  $50.99"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(list_products_tuples, columns=[\"Product\", \"Price\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could use a list of dictionaries with 2 keys:\n",
    "* `\"Product\"`\n",
    "* `\"Price\"`\n",
    "\n",
    "NOTE: we need to remove the `$` from the price and convert to a float!\n",
    "\n",
    "... and why not using list Comprehension :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faded Short Sleeve T-shirts</td>\n",
       "      <td>16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blouse</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Printed Dress</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Printed Dress</td>\n",
       "      <td>50.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Printed Summer Dress</td>\n",
       "      <td>28.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Printed Summer Dress</td>\n",
       "      <td>30.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Printed Chiffon Dress</td>\n",
       "      <td>16.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Printed Chiffon Dress</td>\n",
       "      <td>16.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Faded Short Sleeve T-shirts</td>\n",
       "      <td>16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blouse</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Printed Summer Dress</td>\n",
       "      <td>28.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Printed Dress</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Printed Summer Dress</td>\n",
       "      <td>30.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Printed Dress</td>\n",
       "      <td>50.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Product  Price\n",
       "0   Faded Short Sleeve T-shirts  16.51\n",
       "1                        Blouse  27.00\n",
       "2                 Printed Dress  26.00\n",
       "3                 Printed Dress  50.99\n",
       "4          Printed Summer Dress  28.98\n",
       "5          Printed Summer Dress  30.50\n",
       "6         Printed Chiffon Dress  16.40\n",
       "7         Printed Chiffon Dress  16.40\n",
       "8   Faded Short Sleeve T-shirts  16.51\n",
       "9                        Blouse  27.00\n",
       "10         Printed Summer Dress  28.98\n",
       "11                Printed Dress  26.00\n",
       "12         Printed Summer Dress  30.50\n",
       "13                Printed Dress  50.99"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_products_dict = [\n",
    "    {\n",
    "        \"Product\": p.find(\"a\", class_=\"product-name\").text.strip(),\n",
    "        \"Price\": float(p.find(\"span\", class_=\"price\").text.strip().strip(\"$\")),\n",
    "    }\n",
    "    for p in soup.find_all(\"div\", class_=\"product-container\")\n",
    "]\n",
    "df = pd.DataFrame(list_products_dict)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the type of data with `.dtypes`, to verify that prices are floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product     object\n",
       "Price      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... so now we can draw some graph, get the average, maximum, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.054286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.144574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Price\n",
       "count  14.000000\n",
       "mean   28.054286\n",
       "std    11.144574\n",
       "min    16.400000\n",
       "25%    18.882500\n",
       "50%    27.000000\n",
       "75%    30.120000\n",
       "max    50.990000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project - Part 1: WEB SCRAPPING OF PRODUCTS\n",
    "\n",
    "We will create a small web parsing project that will retrieve prices from different merchant websites:\n",
    "* JD.com (Chinese)\n",
    "* Amazon.co.uk (UK)\n",
    "* NewEgg.com (USA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JD.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting URL for JD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do a research of `Yoga mat` in JD.com, we get the following URL in the address bar:\n",
    "\n",
    "`https://search.jd.com/Search?keyword=yoga%20mat&enc=utf-8&wq=yoga%20mat&pvid=dac61387e9f2464c9ec209af976dc84e`\n",
    "\n",
    "\n",
    "Often the URL can be simplified a bit by removing part of attributes: the following URL is still working:\n",
    "\n",
    "`https://search.jd.com/Search?keyword=yoga%20mat`\n",
    "\n",
    "Therefore, the URL would be:\n",
    "\n",
    "`\"https://search.jd.com/Search?keyword=\"` + **search keywords** (using `%20` for spaces)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformation of spaces to `%20` could be either done by string manipulation (`.replace(\" \", \"%20\")`) or more safely by using the `urllib` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yoga%20mat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import quote\n",
    "\n",
    "quote(\"yoga mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://search.jd.com/Search?keyword=yoga%20mat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_jd_url(keywords):\n",
    "    \"\"\"Return the URL for a JD search based on a keyword\"\"\"\n",
    "    return f\"https://search.jd.com/Search?keyword={quote(keywords)}\"\n",
    "\n",
    "get_jd_url(\"yoga mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎀BONUS🎀\n",
    "\n",
    "A Search has actually several pages: you could modify the function to add an argument with the page number of the search result.\n",
    "\n",
    "JD is using a strange system: an attribute `page` with a value that corresponds to `3` for page 2, `5` for page 3, ...\n",
    "\n",
    "```python\n",
    "def get_jd_url(keywords, page_number=None):\n",
    "    if page_number is None:\n",
    "        return f\"https://search.jd.com/Search?keyword={quote(keywords)}\"\n",
    "    else:\n",
    "        return f\"https://search.jd.com/Search?keyword={quote(keywords)}&page={2 * page_number - 1}\"\n",
    "```\n",
    "\n",
    "You then have to get the maximum number of pages when parsing the first page, and do a loop for all the pages in order to get all the products.\n",
    "\n",
    "For purpose of simplicity, we will stick to the results of the first page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting HTML from JD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use `requests` like we did before to retrieve the HTML content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <script>\n",
      "   window.location.href='https://passport.jd.com/uc/login'\n",
      "  </script>\n",
      " </head>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "def jd_2_soup(keywords):\n",
    "    \"\"\"Get the BeautifulSoup object for a JD search\"\"\"\n",
    "    url = get_jd_url(keywords)\n",
    "    resp = requests.get(url)\n",
    "    return BeautifulSoup(resp.content)\n",
    "\n",
    "soup = jd_2_soup(\"yoga mat\")\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the content is not what we except (the the content of a `<script>`).\n",
    "\n",
    "Probably, JD is using some script to block parsing of data.\n",
    "\n",
    "An alternative is to use the Python Library `requests_html` (that is not provided in Python by default and needs to be installed).\n",
    "\n",
    "This library is more powerful but is a bit more complicated to use: we need to create a Session to parse the code.\n",
    "\n",
    "More information about this library here: https://pypi.org/project/requests-html/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<head>\n",
      " <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      " <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      " <meta content=\"webkit\" name=\"renderer\"/>\n",
      " <meta content=\"max-age=300\" http-equiv=\"Cache-Control\">\n",
      "  <link href=\"//search.jd.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//item.jd.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//list.jd.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//p.3.cn\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//misc.360buyimg.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//nfa.jd.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//d.jd.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//img12.360buyimg.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//img13.360buyimg.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//static.360buyimg.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//csc.jd.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//mercury.jd.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//x.jd.com\" rel=\"dns-prefetch\"/>\n",
      "  <link href=\"//wl.jd.com\" rel=\"dns-prefetch\"/>\n",
      "  <title>\n",
      "   yoga mat - 商品搜索 -...\n"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "def jd_2_soup(keywords):\n",
    "    \"\"\"Get the BeautifulSoup object for a JD search\"\"\"\n",
    "    url = get_jd_url(keywords)\n",
    "    session = HTMLSession()\n",
    "    resp = session.get(url)\n",
    "    return BeautifulSoup(resp.html.html, \"html.parser\")\n",
    "\n",
    "soup = jd_2_soup(\"yoga mat\")\n",
    "print(soup.prettify()[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing products of JD from HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting the information about product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An inspection of the page (i.e. the code) with JD results give the following result:\n",
    "\n",
    "![Inspection of JD](images/inspect_JD.png \"HTML elements for JD product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "* products: `<div>` with class=`gl-i-wrap`\n",
    "* picture: `<img>` and then get the `src`\n",
    "* price: `<div>` with class=`p-price`, and then look for `<i>` (or `strong` if we want the currency)\n",
    "* name: `<div>` with class=`p-name` and then look for `title` attribute or maybe we could just try to get the `.text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 products\n"
     ]
    }
   ],
   "source": [
    "soup_jd = jd_2_soup(\"yoga mat\")\n",
    "products_jd = soup_jd.find_all(\"div\", class_=\"gl-i-wrap\")\n",
    "print(f\"Found {len(products_jd)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Yottoy 天然橡胶5mm瑜伽垫防滑女男初学者加厚加宽加长瑜珈垫健身垫女士\n",
      "【遇见春天】瑜伽活动专场，甄选好物，等你来抢~戳这里查看\n",
      "Price: 148.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prod = products_jd[0]\n",
    "name = prod.find(\"div\", class_=\"p-name\").text.strip()\n",
    "price = float(prod.find(\"div\", class_=\"p-price\").find(\"i\").text.strip())\n",
    "\n",
    "print(f\"\"\"\\\n",
    "Name: {name}\n",
    "Price: {price}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is a bit more complex because has an attribute `source-data-lazy-image` that does some transformation (`src` is changed to something else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\AnsysDev\\_perso_repo\\PY101\\project\\Introduction_to_webparsing.ipynb Cell 40'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000043?line=0'>1</a>\u001b[0m image \u001b[39m=\u001b[39m prod\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mp-img\u001b[39m\u001b[39m\"\u001b[39m})\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m\"\u001b[39m)  \u001b[39m# no \"text\" here because we search the attribute with URL\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000043?line=1'>2</a>\u001b[0m image\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39msrc\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'src'"
     ]
    }
   ],
   "source": [
    "image = prod.find(\"div\", {\"class\": \"p-img\"}).find(\"img\")  # no \"text\" here because we search the attribute with URL\n",
    "image.attrs[\"src\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's forget about the picture then.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "NOTE: If you are curious, you could check the attributes by printing `image` and seeing there is an attribute `data-lazy-img` that returns the following URL:\n",
    "`//img10.360buyimg.com/n7/jfs/t1/195838/14/20844/72023/612dc968E548e1fd9/1a89ed81613ef06d.jpg`. Just add `http:` in front and you get your picture URL:\n",
    "\n",
    "\n",
    "`http://img10.360buyimg.com/n7/jfs/t1/195838/14/20844/72023/612dc968E548e1fd9/1a89ed81613ef06d.jpg`\n",
    "\n",
    "![Picture of Result](http://img10.360buyimg.com/n7/jfs/t1/195838/14/20844/72023/612dc968E548e1fd9/1a89ed81613ef06d.jpg \"The result picture\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transforming into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put everything in a DataFrame (let's stick to name and price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            price\n",
      "count   30.000000\n",
      "mean   149.600000\n",
      "std     27.704848\n",
      "min     95.000000\n",
      "25%    133.250000\n",
      "50%    155.000000\n",
      "75%    166.750000\n",
      "max    199.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yottoy 天然橡胶5mm瑜伽垫防滑女男初学者加厚加宽加长瑜珈垫健身垫女士\\n【遇见春天】...</td>\n",
       "      <td>148.0</td>\n",
       "      <td>http://img10.360buyimg.com/n7/jfs/t1/195838/14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>爱心东东\\t\\n‼lulu·lemon青色鸟瑜伽垫旗舰同款YOGAMAT瑜伽垫女专用初学者加...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>http://img14.360buyimg.com/n7/jfs/t1/220359/31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>爱心东东\\t\\n‼lulu·lemon青色鸟瑜伽垫旗舰同款YOGAMAT瑜伽垫女专用初学者加...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>http://img12.360buyimg.com/n7/jfs/t1/221802/39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>爱心东东\\nYOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 皓月灰+爵士黑...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>http://img12.360buyimg.com/n7/jfs/t1/120008/26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花抹茶绿+坚毅黑【8...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>http://img10.360buyimg.com/n7/jfs/t1/206704/8/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 碳素灰+冰蓝【80cm宽】...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>http://img10.360buyimg.com/n7/jfs/t1/174821/30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花雾霾蓝+藏蓝【80...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>http://img12.360buyimg.com/n7/jfs/t1/210964/14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花雾霾蓝+藏蓝【80...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>http://img10.360buyimg.com/n7/jfs/t1/165540/1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>瑜伽垫 天然橡胶瑜伽垫 5mm加厚防滑初学者 健身垫 带体位线YOGA MAT 淡墨灰-带体...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>http://img10.360buyimg.com/n7/jfs/t1/182970/38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YOGAMAT瑜伽垫tpe男女初学者舞蹈加厚加宽加长防滑健身垫家用地垫 浅灰-黛蓝【61cm...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>http://img11.360buyimg.com/n7/jfs/t1/158094/25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>YOGAMAT瑜伽垫tpe男女初学者舞蹈加厚加宽加长防滑健身垫家用地垫 单色蓝【61cm宽】...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>http://img10.360buyimg.com/n7/jfs/t1/160487/1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>YOGAMAT瑜伽垫tpe男女初学者舞蹈加厚加宽加长防滑健身垫家用地垫 月亮灰【61cm宽】...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>http://img14.360buyimg.com/n7/jfs/t1/165949/2/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>爱心东东\\nYOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 雾霾蓝+藏蓝【...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>http://img13.360buyimg.com/n7/jfs/t1/146940/2/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花粉色+灰色【80c...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>http://img14.360buyimg.com/n7/jfs/t1/167085/18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tpe瑜伽垫80cm宽yogamat加宽加厚加长健身垫运动垫防滑垫沸鱼吾宜轩 香芋紫+暖灰(...</td>\n",
       "      <td>147.0</td>\n",
       "      <td>http://img10.360buyimg.com/n7/jfs/t1/157778/17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>YOGAMAT瑜伽垫tpe男女初学者舞蹈加厚加宽加长防滑健身垫家用地垫 抹茶绿+坚毅黑【61...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>http://img10.360buyimg.com/n7/jfs/t1/168793/36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>瑜伽垫 天然橡胶瑜伽垫 5mm加厚防滑初学者 健身垫 带体位线YOGA MAT 熏烟紫-带体...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>http://img13.360buyimg.com/n7/jfs/t1/194702/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 蓝灰【80cm宽】*背包*...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>http://img13.360buyimg.com/n7/jfs/t1/160485/31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 抹茶绿【80cm宽】*背包...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>http://img14.360buyimg.com/n7/jfs/t1/161293/9/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 月亮灰【80cm宽】*背包...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>http://img11.360buyimg.com/n7/jfs/t1/161776/22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 浅灰+黛蓝【80cm宽】*...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>http://img14.360buyimg.com/n7/jfs/t1/166784/16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 冰粉+浅灰【80cm宽】*...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>http://img11.360buyimg.com/n7/jfs/t1/164888/6/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>瑜伽垫 天然橡胶瑜伽垫 5mm加厚防滑初学者 健身垫 带体位线YOGA MAT 草芽绿-带体...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>http://img12.360buyimg.com/n7/jfs/t1/126747/19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 雾霾蓝+藏蓝【80cm宽】...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>http://img10.360buyimg.com/n7/jfs/t1/156995/22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 碳素灰+冰蓝【80cm宽】...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>http://img12.360buyimg.com/n7/jfs/t1/161635/36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 皓月灰+爵士黑【80cm宽...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>http://img13.360buyimg.com/n7/jfs/t1/159320/35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 抹茶绿+坚毅黑【80cm宽...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>http://img12.360buyimg.com/n7/jfs/t1/171171/21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花浅灰+黛蓝【80c...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>http://img12.360buyimg.com/n7/jfs/t1/156074/30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花皓月灰+爵士黑【8...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>http://img13.360buyimg.com/n7/jfs/t1/158233/1/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花抹茶绿+坚毅黑【8...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>http://img11.360buyimg.com/n7/jfs/t1/169185/1/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  price  \\\n",
       "0   Yottoy 天然橡胶5mm瑜伽垫防滑女男初学者加厚加宽加长瑜珈垫健身垫女士\\n【遇见春天】...  148.0   \n",
       "1   爱心东东\\t\\n‼lulu·lemon青色鸟瑜伽垫旗舰同款YOGAMAT瑜伽垫女专用初学者加...  109.0   \n",
       "2   爱心东东\\t\\n‼lulu·lemon青色鸟瑜伽垫旗舰同款YOGAMAT瑜伽垫女专用初学者加...  101.0   \n",
       "3   爱心东东\\nYOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 皓月灰+爵士黑...  160.0   \n",
       "4   YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花抹茶绿+坚毅黑【8...  140.0   \n",
       "5   YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 碳素灰+冰蓝【80cm宽】...  130.0   \n",
       "6   YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花雾霾蓝+藏蓝【80...  140.0   \n",
       "7   YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花雾霾蓝+藏蓝【80...  169.0   \n",
       "8   瑜伽垫 天然橡胶瑜伽垫 5mm加厚防滑初学者 健身垫 带体位线YOGA MAT 淡墨灰-带体...  199.0   \n",
       "9   YOGAMAT瑜伽垫tpe男女初学者舞蹈加厚加宽加长防滑健身垫家用地垫 浅灰-黛蓝【61cm...  115.0   \n",
       "10  YOGAMAT瑜伽垫tpe男女初学者舞蹈加厚加宽加长防滑健身垫家用地垫 单色蓝【61cm宽】...  105.0   \n",
       "11  YOGAMAT瑜伽垫tpe男女初学者舞蹈加厚加宽加长防滑健身垫家用地垫 月亮灰【61cm宽】...   95.0   \n",
       "12  爱心东东\\nYOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 雾霾蓝+藏蓝【...  131.0   \n",
       "13  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花粉色+灰色【80c...  169.0   \n",
       "14  tpe瑜伽垫80cm宽yogamat加宽加厚加长健身垫运动垫防滑垫沸鱼吾宜轩 香芋紫+暖灰(...  147.0   \n",
       "15  YOGAMAT瑜伽垫tpe男女初学者舞蹈加厚加宽加长防滑健身垫家用地垫 抹茶绿+坚毅黑【61...  115.0   \n",
       "16  瑜伽垫 天然橡胶瑜伽垫 5mm加厚防滑初学者 健身垫 带体位线YOGA MAT 熏烟紫-带体...  199.0   \n",
       "17  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 蓝灰【80cm宽】*背包*...  150.0   \n",
       "18  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 抹茶绿【80cm宽】*背包...  150.0   \n",
       "19  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 月亮灰【80cm宽】*背包...  150.0   \n",
       "20  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 浅灰+黛蓝【80cm宽】*...  160.0   \n",
       "21  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 冰粉+浅灰【80cm宽】*...  160.0   \n",
       "22  瑜伽垫 天然橡胶瑜伽垫 5mm加厚防滑初学者 健身垫 带体位线YOGA MAT 草芽绿-带体...  199.0   \n",
       "23  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 雾霾蓝+藏蓝【80cm宽】...  160.0   \n",
       "24  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 碳素灰+冰蓝【80cm宽】...  160.0   \n",
       "25  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 皓月灰+爵士黑【80cm宽...  160.0   \n",
       "26  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 抹茶绿+坚毅黑【80cm宽...  160.0   \n",
       "27  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花浅灰+黛蓝【80c...  169.0   \n",
       "28  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花皓月灰+爵士黑【8...  169.0   \n",
       "29  YOGAMAT瑜伽垫女tpe80CM加宽加厚健身垫初学者三件套毯 曼陀罗花抹茶绿+坚毅黑【8...  169.0   \n",
       "\n",
       "                                                image  \n",
       "0   http://img10.360buyimg.com/n7/jfs/t1/195838/14...  \n",
       "1   http://img14.360buyimg.com/n7/jfs/t1/220359/31...  \n",
       "2   http://img12.360buyimg.com/n7/jfs/t1/221802/39...  \n",
       "3   http://img12.360buyimg.com/n7/jfs/t1/120008/26...  \n",
       "4   http://img10.360buyimg.com/n7/jfs/t1/206704/8/...  \n",
       "5   http://img10.360buyimg.com/n7/jfs/t1/174821/30...  \n",
       "6   http://img12.360buyimg.com/n7/jfs/t1/210964/14...  \n",
       "7   http://img10.360buyimg.com/n7/jfs/t1/165540/1/...  \n",
       "8   http://img10.360buyimg.com/n7/jfs/t1/182970/38...  \n",
       "9   http://img11.360buyimg.com/n7/jfs/t1/158094/25...  \n",
       "10  http://img10.360buyimg.com/n7/jfs/t1/160487/1/...  \n",
       "11  http://img14.360buyimg.com/n7/jfs/t1/165949/2/...  \n",
       "12  http://img13.360buyimg.com/n7/jfs/t1/146940/2/...  \n",
       "13  http://img14.360buyimg.com/n7/jfs/t1/167085/18...  \n",
       "14  http://img10.360buyimg.com/n7/jfs/t1/157778/17...  \n",
       "15  http://img10.360buyimg.com/n7/jfs/t1/168793/36...  \n",
       "16  http://img13.360buyimg.com/n7/jfs/t1/194702/20...  \n",
       "17  http://img13.360buyimg.com/n7/jfs/t1/160485/31...  \n",
       "18  http://img14.360buyimg.com/n7/jfs/t1/161293/9/...  \n",
       "19  http://img11.360buyimg.com/n7/jfs/t1/161776/22...  \n",
       "20  http://img14.360buyimg.com/n7/jfs/t1/166784/16...  \n",
       "21  http://img11.360buyimg.com/n7/jfs/t1/164888/6/...  \n",
       "22  http://img12.360buyimg.com/n7/jfs/t1/126747/19...  \n",
       "23  http://img10.360buyimg.com/n7/jfs/t1/156995/22...  \n",
       "24  http://img12.360buyimg.com/n7/jfs/t1/161635/36...  \n",
       "25  http://img13.360buyimg.com/n7/jfs/t1/159320/35...  \n",
       "26  http://img12.360buyimg.com/n7/jfs/t1/171171/21...  \n",
       "27  http://img12.360buyimg.com/n7/jfs/t1/156074/30...  \n",
       "28  http://img13.360buyimg.com/n7/jfs/t1/158233/1/...  \n",
       "29  http://img11.360buyimg.com/n7/jfs/t1/169185/1/...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_df_jd(keywords):\n",
    "    \"\"\"Get a dataframe for the results of a JD search\"\"\"\n",
    "    soup = jd_2_soup(\"yoga mat\")\n",
    "    products = soup.find_all(\"div\", {\"class\": \"gl-i-wrap\"})\n",
    "    data_products = [\n",
    "\n",
    "        {\n",
    "            \"name\": p.find(\"div\", class_=\"p-name\").text.strip(),\n",
    "            \"price\": float(p.find(\"div\", class_=\"p-price\").find(\"i\").text.strip()),\n",
    "            \"image\": \"http:\" + p.find(\"div\", class_=\"p-img\").find(\"img\").attrs[\"data-lazy-img\"].strip(),\n",
    "        }\n",
    "        for p in products\n",
    "    ]\n",
    "    return pd.DataFrame(data_products)\n",
    "\n",
    "df = get_df_jd(\"yoga mat\")\n",
    "print(df.describe())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon UK\n",
    "\n",
    "*Note: not Amazon USA, because it is protected against web scrapping*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now scrapping products with their prices from https://www.amazon.co.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting URL from Amazon US\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at how we defined a function to get URL for a JD search and adapt to Amazon UK.\n",
    "\n",
    "Note: Amazon is using `+` to separate keywords instead of `%20` in its website.\n",
    "\n",
    "... but if you use `%20` it is actually working as well.\n",
    "\n",
    "You can try: [https://www.amazon.co.uk/s?k=yoga%20mat](https://www.amazon.co.uk/s?k=yoga%20mat)   [**spoiler alert**: it is replaced automatically]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.amazon.co.uk/s?k=yoga%20mat'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_amazon_url(keywords):\n",
    "    \"\"\"Return the URL for an Amazon search based on a keyword\"\"\"\n",
    "    return f\"https://...\"  # TODO: replace the ... by the correct content\n",
    "\n",
    "get_amazon_url(\"yoga mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting HTML from Amazon UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"a-no-js\" data-19ax5a9jf=\"dingo\" lang=\"en-gb\">\n",
      " <!-- sp:feature:head-start -->\n",
      " <head>\n",
      "  <script>\n",
      "   var aPageStart = (new Date()).getTime();\n",
      "  </script>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <!-- sp:end-feature:head-start -->\n",
      "  <script type=\"text/javascript\">\n",
      "   var ue_t0=ue_t0||+\n",
      "......\n",
      " && ue.count && ue.count('CSMLibrarySize', 80956)\n",
      "   </script>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "<!--       _\n",
      "       .__(.)< (MEOW)\n",
      "        \\___)   \n",
      " ~~~~~~~~~~~~~~~~~~-->\n",
      "<!-- sp:eh:ttjenL6L8DRTMz+S627gFEd4b5OYYqkitIa9xbEtCA1gC5vL3Nj9x941LhuMVwUjrR48qy5MmjJwu3av1tapnJ3i2mmCPoR2fgGfeFOI4oOiN8JhsMjnkg== -->\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "\n",
    "# It is almost a copy paste of the JD equivalent function\n",
    "\n",
    "def amazon_2_soup(keywords):\n",
    "    \"\"\"Get the BeautifulSoup object for a Amazon UK search\"\"\"\n",
    "    url = get_amazon_url(keywords)\n",
    "    session = HTMLSession()\n",
    "    resp = session.get(url)\n",
    "    return BeautifulSoup(resp.html.html, \"html.parser\")\n",
    "\n",
    "soup = amazon_2_soup(\"yoga mat\")\n",
    "print(soup.prettify()[:300] + \"\\n......\\n\" + soup.prettify()[-300:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing products of Amazon UK from HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing inspection, we can notice that all results are inside a `<div class=\"sg-col-inner\"...>`.\n",
    "\n",
    "However, if we look at the first similar result, this is what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"sg-col-inner\">\\n <div class=\"a-section a-spacing-small a-spacing-top-small\">\\n  <span>\\n   1-48 of 286 results for\\n  </span>\\n  <span>\\n  </span>\\n  <span class=\"a-color-state a-text-bold\">\\n   \"yoga mat\"\\n  </span>\\n </div>\\n</div>'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = amazon_2_soup(\"yoga mat\")\n",
    "first_prod = soup.find(\"div\", class_=\"sg-col-inner\")\n",
    "first_prod.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So basically, this is a block at the top with the total number of results:\n",
    "\n",
    "![Picture of 1st \"Result\"](images/first_result.png \"The total number of results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... by looking a bit further, we can see that the all the results are inside a `<div class=\"s-matching-dir\">`:\n",
    "\n",
    "We will first get this element, and then search inside for all the `<div class=\"sg-col-inner\"...>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87 products\n"
     ]
    }
   ],
   "source": [
    "soup = amazon_2_soup(\"yoga mat\")\n",
    "products = soup.find(\"div\", class_=\"s-matching-dir\").find_all(\"div\", class_=\"sg-col-inner\")\n",
    "print(f\"Found {len(products)} products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the code of first result:\n",
    "\n",
    "(there are some link to pictures: just copy-paste in a browser to verify that it is a picture of a yoga mat:\n",
    "`https://m.media-amazon.com/images/I/71pSktIgxSL._AC_UL320_.jpg`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"sg-col-inner\">\\n <div id=\"s-skipLinkTargetForMainSearchResults\" tabindex=\"-1\">\\n </div>\\n <span class=\"rush-component\" data-component-type=\"s-top-slot\">\\n </span>\\n <span class=\"rush-component\" data-component-type=\"s-top-banner\">\\n </span>\\n <span class=\"rush-component s-latency-cf-section\" data-component-type=\"s-search-results\">\\n  <div class=\"s-result-list s-search-results sg-row\">\\n   <div class=\"s-border-top-overlap aok-hidden\">\\n   </div>\\n  </div>\\n  <div class=\"s-main-slot s-result-list s-search-results sg-row\">\\n   <img alt=\"\" class=\"s-prefetch-image\" src=\"https://m.media-amazon.com/images/I/71pSktIgxSL._AC_UL320_.jpg\" srcset=\"https://m.media-amazon.com/images/I/71pSktIgxSL._AC_UL320_.jpg 1x, https://m.media-amazon.com/images/I/71pSktIgxSL._AC_UL480_QL65_.jpg 1.5x, https://m.media-amazon.com/images/I/71pSktIgxSL._AC_UL640_QL65_.jpg 2x, https://m.media-amazon.com/images/I/71pSktIgxSL._AC_UL800_QL65_.jpg 2.5x, https://m.media-amazon.com/images/I/71pSktIgxSL._AC_UL960_QL65_.jpg 3x\"'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[0].prettify()[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parsing of Product in Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code of a product result is the following\n",
    "\n",
    "![Code of a product](images/amazon_uk_products.png \"A product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have to extract:\n",
    "1. The name\n",
    "2. The price\n",
    "\n",
    "💡TIP: for the price, take care of the following:\n",
    "* Don't get several prices (we can see that it appears twice)\n",
    "* Remove the currency with `.strip(\"£\")`\n",
    "* Convert to float to store a number and not a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Ellipsis\n",
      "Price: Ellipsis\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prod = products[0]\n",
    "name = ...\n",
    "price = ...\n",
    "# TODO: Implement to get the name and price of product (remove the ... and replace with correct code)\n",
    "\n",
    "print(f\"\"\"\\\n",
    "Name: {name}\n",
    "Price: {price}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we did for JD, create a function to get a DataFrame for Amazon by re-using the code we just got to retrieve a product name and price (you can ignore the picture unless you feel bold enough to try).\n",
    "\n",
    "🛎️IMPORTANT: the list of products might contain items without a price: you can filter by adding a condition `if prod.find(\"span\", class_=\"a-price\")` when doing a loop on all products `prod` of the list of products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\AnsysDev\\_perso_repo\\PY101\\project\\Introduction_to_webparsing.ipynb Cell 69'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=4'>5</a>\u001b[0m     data_products \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=5'>6</a>\u001b[0m         {\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=6'>7</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=10'>11</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=11'>12</a>\u001b[0m     ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=12'>13</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(data_products)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=14'>15</a>\u001b[0m df \u001b[39m=\u001b[39m get_df_amazon(\u001b[39m\"\u001b[39;49m\u001b[39myoga mat\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdescribe())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=16'>17</a>\u001b[0m df\n",
      "\u001b[1;32md:\\AnsysDev\\_perso_repo\\PY101\\project\\Introduction_to_webparsing.ipynb Cell 69'\u001b[0m in \u001b[0;36mget_df_amazon\u001b[1;34m(keywords)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=2'>3</a>\u001b[0m soup \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=3'>4</a>\u001b[0m products \u001b[39m=\u001b[39m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=4'>5</a>\u001b[0m data_products \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=5'>6</a>\u001b[0m     {\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=6'>7</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=7'>8</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mprice\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=8'>9</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m products\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=10'>11</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=11'>12</a>\u001b[0m ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/AnsysDev/_perso_repo/PY101/project/Introduction_to_webparsing.ipynb#ch0000070?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(data_products)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
     ]
    }
   ],
   "source": [
    "# TODO: Replace ... by correct code\n",
    "\n",
    "def get_df_amazon(keywords):\n",
    "    \"\"\"Get a dataframe for the results of an Amazon search\"\"\"\n",
    "    soup = ...\n",
    "    products = ...\n",
    "    data_products = [\n",
    "        {\n",
    "            \"name\": ...,\n",
    "            \"price\": ...,\n",
    "        }\n",
    "        for p in products\n",
    "        if ...\n",
    "    ]\n",
    "    return pd.DataFrame(data_products)\n",
    "\n",
    "df = get_df_amazon(\"yoga mat\")\n",
    "print(df.describe())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NewEgg\n",
    "\n",
    "[OPTIONAL CHALLENGE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you are familiar with the basics of Web Scrapping from a merchant site, try doing the same with NewEgg:\n",
    "\n",
    "https://www.newegg.com/\n",
    "\n",
    "The purpose is to create a function `get_df_newegg` that create a DataFrame based on keywords.\n",
    "\n",
    "Good luck!!\n",
    "\n",
    "💡#1:  For the prices, some prices are missing, so you can filter with this: `if prod.find(\"li\", class_=\"price-current\").text`\n",
    "\n",
    "💡#2: The prices contain currency but also a number or offer and a strange character `\"–\"` (a sort of long hyphen): you can use the following function to extract the float value from the price as a string:\n",
    "```python\n",
    "def get_newegg_price(price_current):\n",
    "    \"\"\"Process the price of a result (string) and return the string\"\"\"\n",
    "    import re\n",
    "    return float(re.sub(r'.*?([\\d\\.]+).*', r'\\1', price_current))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "443f0811113689e9d4171a4680aa69df780800e5e0d4737224dc917c77f16b5f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
