{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Web Parsing\n"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction to Web Parsing"]},{"cell_type":"markdown","metadata":{},"source":["Web Parsing has 4 main steps\n","\n","1. Create the URL that correspond to a search or a page you want\n","2. Get the content of the HTML page based on the URL\n","3. Parsing the content of the HTML page to retrieve the data you want\n","4. Storing / Processing this data\n","\n","And about these steps:\n","* #1 is quite easy\n","* #2 could be complex if the page is protected by password or a mechanism to prevent web scrapping\n","* #3 is OK but you need to understand a bit about HTML\n","* #4 is just Python stuff"]},{"cell_type":"markdown","metadata":{},"source":["### Interactive Learning\n","\n","A fun and interactive way to learn has been created here:\n","\n","https://quizizz.com/join/lesson/621b9031fbcbe9001d6b30c2/start\n","\n","This refers to the two following links introducing respectively HTML and Web Parsing:\n","* https://www.w3schools.com/html/html_intro.asp\n","* https://medium.com/opex-analytics/simple-web-scraping-in-python-90d6fddfaeca\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["TIP: If you are using Safari, here is how to have the \"Inspect\" menu:\n","\n","https://www.idownloadblog.com/2019/06/21/how-to-use-safari-web-inspector-ios-mac/"]},{"cell_type":"markdown","metadata":{},"source":["### Example of simple Web Parsing\n","\n","In this introduction, we will try to extract product names and prices from this website:\n","http://automationpractice.com/index.php\n","\n","*NOTE: this is a dummy merchant website created to practice Web Test Automation and Web Scrapping.*"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:38.631063Z","iopub.status.busy":"2022-02-28T15:45:38.630649Z","iopub.status.idle":"2022-02-28T15:45:39.847872Z","shell.execute_reply":"2022-02-28T15:45:39.84694Z","shell.execute_reply.started":"2022-02-28T15:45:38.630996Z"},"trusted":true},"outputs":[],"source":["import requests\n","\n","from bs4 import BeautifulSoup\n","\n","url = \"http://automationpractice.com/index.php\"\n","\n","# makes a request to the web page and gets its HTML\n","r = requests.get(url)\n","\n","# stores the HTML page in 'soup', a BeautifulSoup object\n","soup = BeautifulSoup(r.content)\n"]},{"cell_type":"markdown","metadata":{},"source":["We can show the content stored in the \"soup\" with `soup.prettify()`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:39.850244Z","iopub.status.busy":"2022-02-28T15:45:39.849925Z","iopub.status.idle":"2022-02-28T15:45:39.876241Z","shell.execute_reply":"2022-02-28T15:45:39.875301Z","shell.execute_reply.started":"2022-02-28T15:45:39.850203Z"},"trusted":true},"outputs":[],"source":["print(soup.prettify()[:1000] + \"...\")"]},{"cell_type":"markdown","metadata":{},"source":["By doing inspection of the page, we can notice that:\n","* All products are in `<div clas=\"product-container\">`\n","* The name of the product is (inside the product) in `<a class=\"product-name\">`\n","* The price of the product is (inside the product) in `<span class=\"price product-price\">` (so searching for either class `price` or `product-price`)\n","\n","In BeautifulSoup, we will use:\n","* `.find_all(...)` to search all products\n","* `.find(...)` to search an element\n","* `class_=\"...\"` to specify the class\n","\n","**IMPORTANT**:\n","Note the underscore `_`  after \"class\" (`class_`) because `class` is a keyword used in Python language.\n","\n","So to get products names and prices, we could something like this:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:39.877507Z","iopub.status.busy":"2022-02-28T15:45:39.877306Z","iopub.status.idle":"2022-02-28T15:45:39.89695Z","shell.execute_reply":"2022-02-28T15:45:39.896134Z","shell.execute_reply.started":"2022-02-28T15:45:39.877482Z"},"trusted":true},"outputs":[],"source":["list_products = {}\n","\n","for product in soup.find_all(\"div\", class_=\"product-container\"):\n","    name = product.find(\"a\", class_=\"product-name\").text.strip()\n","    price = product.find(\"span\", class_=\"price\").text.strip()\n","    list_products[name] = price\n","\n","list_products"]},{"cell_type":"markdown","metadata":{},"source":["... BUT we only get 5 products because some products have the same name: so it's better to store all data in a list of Tuples for example"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:39.898359Z","iopub.status.busy":"2022-02-28T15:45:39.897961Z","iopub.status.idle":"2022-02-28T15:45:39.912705Z","shell.execute_reply":"2022-02-28T15:45:39.911817Z","shell.execute_reply.started":"2022-02-28T15:45:39.898325Z"},"trusted":true},"outputs":[],"source":["list_products_tuples = []\n","\n","for product in soup.find_all(\"div\", class_=\"product-container\"):\n","    name = product.find(\"a\", class_=\"product-name\").text.strip()\n","    price = product.find(\"span\", class_=\"price\").text.strip()\n","    list_products_tuples.append((name, price))  # double parentheses here because we need a tuple\n","\n","list_products_tuples"]},{"cell_type":"markdown","metadata":{},"source":["Usually we will use `pandas`, which is THE library for data science.\n","\n","The data is stored in a `DataFrame`, which is the equivalent of an Excel Table.\n","The usual way to create a Data Frame is:\n","* from an Excel or .csv file if we have one\n","* from a list of tuples, that will correspond to the values in columns\n","* from a list of dictionaries, that will create the needed columns and their headers\n","\n","Here, we could use a list of tuples we just created."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:39.914924Z","iopub.status.busy":"2022-02-28T15:45:39.914678Z","iopub.status.idle":"2022-02-28T15:45:39.941785Z","shell.execute_reply":"2022-02-28T15:45:39.94083Z","shell.execute_reply.started":"2022-02-28T15:45:39.914891Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.DataFrame(list_products_tuples, columns=[\"Product\", \"Price\"])\n","df"]},{"cell_type":"markdown","metadata":{},"source":["Or we could use a list of dictionaries with 2 keys:\n","* `\"Product\"`\n","* `\"Price\"`\n","\n","NOTE: we need to remove the `$` from the price and convert to a float!\n","\n","... and why not using list Comprehension :)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:39.943683Z","iopub.status.busy":"2022-02-28T15:45:39.943065Z","iopub.status.idle":"2022-02-28T15:45:39.965531Z","shell.execute_reply":"2022-02-28T15:45:39.964981Z","shell.execute_reply.started":"2022-02-28T15:45:39.94364Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","list_products_dict = [\n","    {\n","        \"Product\": p.find(\"a\", class_=\"product-name\").text.strip(),\n","        \"Price\": float(p.find(\"span\", class_=\"price\").text.strip().strip(\"$\")),\n","    }\n","    for p in soup.find_all(\"div\", class_=\"product-container\")\n","]\n","df = pd.DataFrame(list_products_dict)\n","df\n"]},{"cell_type":"markdown","metadata":{},"source":["We can check the type of data with `.dtypes`, to verify that prices are floats."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:39.966883Z","iopub.status.busy":"2022-02-28T15:45:39.96637Z","iopub.status.idle":"2022-02-28T15:45:39.973028Z","shell.execute_reply":"2022-02-28T15:45:39.972489Z","shell.execute_reply.started":"2022-02-28T15:45:39.966849Z"},"trusted":true},"outputs":[],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["... so now we can draw some graph, get the average, maximum, ..."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:39.974406Z","iopub.status.busy":"2022-02-28T15:45:39.97404Z","iopub.status.idle":"2022-02-28T15:45:40.002719Z","shell.execute_reply":"2022-02-28T15:45:40.001841Z","shell.execute_reply.started":"2022-02-28T15:45:39.974377Z"},"trusted":true},"outputs":[],"source":["df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:40.004516Z","iopub.status.busy":"2022-02-28T15:45:40.00398Z","iopub.status.idle":"2022-02-28T15:45:40.29374Z","shell.execute_reply":"2022-02-28T15:45:40.292837Z","shell.execute_reply.started":"2022-02-28T15:45:40.00448Z"},"trusted":true},"outputs":[],"source":["df.plot.hist()"]},{"cell_type":"markdown","metadata":{},"source":["## Project - Part 1: WEB SCRAPPING OF PRODUCTS\n","\n","We will create a small web parsing project that will retrieve prices from different merchant websites:\n","* JD.com (Chinese)\n","* Amazon.co.uk(UK)\n","* NewEgg.com (USA)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### JD.com"]},{"cell_type":"markdown","metadata":{},"source":["#### Getting URL for JD"]},{"cell_type":"markdown","metadata":{},"source":["If you do a research of `Yoga mat` in JD.com, we get the following URL in the address bar:\n","\n","`https://search.jd.com/Search?keyword=yoga%20mat&enc=utf-8&wq=yoga%20mat&pvid=dac61387e9f2464c9ec209af976dc84e`\n","\n","\n","Often the URL can be simplified a bit by removing part of attributes: the following URL is still working:\n","\n","`https://search.jd.com/Search?keyword=yoga%20mat`\n","\n","Therefore, the URL would be:\n","\n","`\"https://search.jd.com/Search?keyword=\"` + **search keywords** (using `%20` for spaces)\n"]},{"cell_type":"markdown","metadata":{},"source":["The transformation of spaces to `%20` could be either done by string manipulation (`.replace(\" \", \"%20\")`) or more safely by using the `urllib` library."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:40.29582Z","iopub.status.busy":"2022-02-28T15:45:40.294988Z","iopub.status.idle":"2022-02-28T15:45:40.302947Z","shell.execute_reply":"2022-02-28T15:45:40.301946Z","shell.execute_reply.started":"2022-02-28T15:45:40.295776Z"},"trusted":true},"outputs":[],"source":["from urllib.parse import quote\n","\n","quote(\"yoga mat\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:40.30495Z","iopub.status.busy":"2022-02-28T15:45:40.304307Z","iopub.status.idle":"2022-02-28T15:45:40.313522Z","shell.execute_reply":"2022-02-28T15:45:40.312716Z","shell.execute_reply.started":"2022-02-28T15:45:40.304921Z"},"trusted":true},"outputs":[],"source":["def get_jd_url(keywords):\n","    \"\"\"Return the URL for a JD search based on a keyword\"\"\"\n","    return f\"https://search.jd.com/Search?keyword={quote(keywords)}\"\n","\n","get_jd_url(\"yoga mat\")"]},{"cell_type":"markdown","metadata":{},"source":["üéÄBONUSüéÄ\n","\n","A Search has actually several pages: you could modify the function to add an argument with the page number of the search result.\n","\n","JD is using a strange system: an attribute `page` with a value that corresponds to `3` for page 2, `5` for page 3, ...\n","\n","```python\n","def get_jd_url(keywords, page_number=None):\n","    if page_number is None:\n","        return f\"https://search.jd.com/Search?keyword={quote(keywords)}\"\n","    else:\n","        return f\"https://search.jd.com/Search?keyword={quote(keywords)}&page={2 * page_number - 1}\"\n","```\n","\n","You then have to get the maximum number of pages when parsing the first page, and do a loop for all the pages in order to get all the products.\n","\n","For purpose of simplicity, we will stick to the results of the first page."]},{"cell_type":"markdown","metadata":{},"source":["#### Getting HTML from JD"]},{"cell_type":"markdown","metadata":{},"source":["Let's try to use `requests` like we did before to retrieve the HTML content."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:40.314745Z","iopub.status.busy":"2022-02-28T15:45:40.314535Z","iopub.status.idle":"2022-02-28T15:45:41.771608Z","shell.execute_reply":"2022-02-28T15:45:41.770497Z","shell.execute_reply.started":"2022-02-28T15:45:40.314719Z"},"trusted":true},"outputs":[],"source":["def jd_2_soup(keywords):\n","    \"\"\"Get the BeautifulSoup object for a JD search\"\"\"\n","    url = get_jd_url(keywords)\n","    resp = requests.get(url)\n","    return BeautifulSoup(resp.content)\n","\n","soup = jd_2_soup(\"yoga mat\")\n","print(soup.prettify())"]},{"cell_type":"markdown","metadata":{},"source":["We can see that the content is not what we except (the the content of a `<script>`).\n","\n","Probably, JD is using some script to block parsing of data.\n","\n","An alternative is to use the Python Library `requests_html` (that is not provided in Python by default and needs to be installed with `pip`).\n","\n","This library is more powerful but is a bit more complicated to use: we need to create a Session to parse the code.\n","\n","More information about this library here: https://pypi.org/project/requests-html/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:41.775277Z","iopub.status.busy":"2022-02-28T15:45:41.774971Z","iopub.status.idle":"2022-02-28T15:45:49.116218Z","shell.execute_reply":"2022-02-28T15:45:49.115378Z","shell.execute_reply.started":"2022-02-28T15:45:41.775243Z"},"trusted":true},"outputs":[],"source":["# Note: you might have some warnings \"about Running pip as the 'root' user can result in broken permission\"\n","# ... it's not a problem, just ignore it\n","%pip install -q requests_html"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:49.121279Z","iopub.status.busy":"2022-02-28T15:45:49.120895Z","iopub.status.idle":"2022-02-28T15:45:50.543902Z","shell.execute_reply":"2022-02-28T15:45:50.543175Z","shell.execute_reply.started":"2022-02-28T15:45:49.121235Z"},"trusted":true},"outputs":[],"source":["from requests_html import HTMLSession\n","\n","def jd_2_soup(keywords):\n","    \"\"\"Get the BeautifulSoup object for a JD search\"\"\"\n","    url = get_jd_url(keywords)\n","    session = HTMLSession()\n","    resp = session.get(url)\n","    return BeautifulSoup(resp.html.html, \"html.parser\")\n","\n","soup = jd_2_soup(\"yoga mat\")\n","print(soup.prettify()[:1000] + \"...\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Parsing products of JD from HTML\n"]},{"cell_type":"markdown","metadata":{},"source":["##### Getting the information about product"]},{"cell_type":"markdown","metadata":{},"source":["An inspection of the page (i.e. the code) with JD results give the following result:\n","\n","![Inspection of JD](images/inspect_JD.png)"]},{"cell_type":"markdown","metadata":{},"source":["To summarize:\n","* products: `<div>` with class=`gl-i-wrap`\n","* picture: `<img>` and then get the `src`\n","* price: `<div>` with class=`p-price`, and then look for `<i>` (or `strong` if we want the currency)\n","* name: `<div>` with class=`p-name` and then look for `title` attribute or maybe we could just try to get the `.text`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:50.545333Z","iopub.status.busy":"2022-02-28T15:45:50.544851Z","iopub.status.idle":"2022-02-28T15:45:51.658345Z","shell.execute_reply":"2022-02-28T15:45:51.657624Z","shell.execute_reply.started":"2022-02-28T15:45:50.545298Z"},"trusted":true},"outputs":[],"source":["soup_jd = jd_2_soup(\"yoga mat\")\n","products_jd = soup_jd.find_all(\"div\", class_=\"gl-i-wrap\")\n","print(f\"Found {len(products_jd)} products\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:45:51.660082Z","iopub.status.busy":"2022-02-28T15:45:51.659317Z","iopub.status.idle":"2022-02-28T15:45:51.666666Z","shell.execute_reply":"2022-02-28T15:45:51.665703Z","shell.execute_reply.started":"2022-02-28T15:45:51.660032Z"},"trusted":true},"outputs":[],"source":["prod = products_jd[0]\n","name = prod.find(\"div\", class_=\"p-name\").text.strip()\n","price = float(prod.find(\"div\", class_=\"p-price\").find(\"i\").text.strip())\n","\n","print(f\"\"\"\\\n","Name: {name}\n","Price: {price}\n","\"\"\")"]},{"cell_type":"markdown","metadata":{},"source":["The image is a bit more complex because has an attribute `source-data-lazy-image` that does some transformation (`src` is changed to something else)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:50:46.612683Z","iopub.status.busy":"2022-02-28T15:50:46.61211Z","iopub.status.idle":"2022-02-28T15:50:46.618029Z","shell.execute_reply":"2022-02-28T15:50:46.616724Z","shell.execute_reply.started":"2022-02-28T15:50:46.61264Z"},"trusted":true},"outputs":[],"source":["image = prod.find(\"div\", {\"class\": \"p-img\"}).find(\"img\")  # no \"text\" here because we search the attribute with URL\n","\n","if \"src\" not in image.attrs:\n","    print(\"‚ö†WARNING‚ö† 'src' not found in attributes\")"]},{"cell_type":"markdown","metadata":{},"source":["Let's forget about the picture then.\n","\n","---\n","\n","\n","NOTE: If you are curious, you could check the attributes by printing `image` and seeing there is an attribute `data-lazy-img` that returns the following URL:\n","`//img10.360buyimg.com/n7/jfs/t1/195838/14/20844/72023/612dc968E548e1fd9/1a89ed81613ef06d.jpg`. Just add `http:` in front and you get your picture URL:\n","\n","\n","`http://img10.360buyimg.com/n7/jfs/t1/195838/14/20844/72023/612dc968E548e1fd9/1a89ed81613ef06d.jpg`\n","\n","![Picture of Result](http://img10.360buyimg.com/n7/jfs/t1/195838/14/20844/72023/612dc968E548e1fd9/1a89ed81613ef06d.jpg \"The result picture\")\n"]},{"cell_type":"markdown","metadata":{},"source":["##### Transforming into a DataFrame"]},{"cell_type":"markdown","metadata":{},"source":["We can now put everything in a DataFrame (let's stick to name and price)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-28T15:46:04.409299Z","iopub.status.busy":"2022-02-28T15:46:04.408591Z","iopub.status.idle":"2022-02-28T15:46:06.073171Z","shell.execute_reply":"2022-02-28T15:46:06.072184Z","shell.execute_reply.started":"2022-02-28T15:46:04.409246Z"},"trusted":true},"outputs":[],"source":["def get_df_jd(keywords):\n","    \"\"\"Get a dataframe for the results of a JD search\"\"\"\n","    soup = jd_2_soup(\"yoga mat\")\n","    products = soup.find_all(\"div\", {\"class\": \"gl-i-wrap\"})\n","    data_products = [\n","\n","        {\n","            \"name\": p.find(\"div\", class_=\"p-name\").text.strip(),\n","            \"price\": float(p.find(\"div\", class_=\"p-price\").find(\"i\").text.strip()),\n","            \"image\": \"http:\" + p.find(\"div\", class_=\"p-img\").find(\"img\").attrs[\"data-lazy-img\"].strip(),\n","        }\n","        for p in products\n","    ]\n","    return pd.DataFrame(data_products)\n","\n","df = get_df_jd(\"yoga mat\")\n","print(df.describe())\n","df"]},{"cell_type":"markdown","metadata":{},"source":["### Amazon UK\n","\n","*Note: not Amazon USA, because it is protected against web scrapping*\n"]},{"cell_type":"markdown","metadata":{},"source":["We are now scrapping products with their prices from https://www.amazon.co.uk"]},{"cell_type":"markdown","metadata":{},"source":["#### Getting URL from Amazon UK\n"]},{"cell_type":"markdown","metadata":{},"source":["Look at how we defined a function to get URL for a JD search and adapt to Amazon UK.\n","\n","Note: Amazon is using `+` to separate keywords instead of `%20` in its website.\n","\n","... but if you use `%20` it is actually working as well.\n","\n","You can try: [https://www.amazon.co.uk/s?k=yoga%20mat](https://www.amazon.co.uk/s?k=yoga%20mat)   [**spoiler alert**: it is replaced automatically]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-28T15:45:51.703846Z","iopub.status.idle":"2022-02-28T15:45:51.704179Z","shell.execute_reply":"2022-02-28T15:45:51.704Z","shell.execute_reply.started":"2022-02-28T15:45:51.703985Z"},"trusted":true},"outputs":[],"source":["def get_amazon_url(keywords):\n","    \"\"\"Return the URL for an Amazon search based on a keyword\"\"\"\n","    return f\"https://...\"  # TODO: replace the ... by the correct content\n","\n","get_amazon_url(\"yoga mat\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Getting HTML from Amazon UK"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-28T15:45:51.706119Z","iopub.status.idle":"2022-02-28T15:45:51.706775Z","shell.execute_reply":"2022-02-28T15:45:51.706619Z","shell.execute_reply.started":"2022-02-28T15:45:51.706599Z"},"trusted":true},"outputs":[],"source":["from requests_html import HTMLSession\n","\n","# It is almost a copy paste of the JD equivalent function\n","\n","def amazon_2_soup(keywords):\n","    \"\"\"Get the BeautifulSoup object for a Amazon UK search\"\"\"\n","    url = get_amazon_url(keywords)\n","    session = HTMLSession()\n","    resp = session.get(url)\n","    return BeautifulSoup(resp.html.html, \"html.parser\")\n","\n","soup = amazon_2_soup(\"yoga mat\")\n","print(soup.prettify()[:300] + \"\\n......\\n\" + soup.prettify()[-300:])"]},{"cell_type":"markdown","metadata":{},"source":["#### Parsing products of Amazon UK from HTML"]},{"cell_type":"markdown","metadata":{},"source":["When doing inspection, we can notice that all results are inside a `<div class=\"sg-col-inner\"...>`.\n","\n","However, if we look at the first similar result, this is what we get:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-28T15:45:51.707931Z","iopub.status.idle":"2022-02-28T15:45:51.70858Z","shell.execute_reply":"2022-02-28T15:45:51.708431Z","shell.execute_reply.started":"2022-02-28T15:45:51.708412Z"},"trusted":true},"outputs":[],"source":["soup = amazon_2_soup(\"yoga mat\")\n","first_prod = soup.find(\"div\", class_=\"sg-col-inner\")\n","first_prod.prettify()"]},{"cell_type":"markdown","metadata":{},"source":["So basically, this is a block at the top with the total number of results:\n","\n","![Picture of 1st \"Result\"](images/first_result.png)"]},{"cell_type":"markdown","metadata":{},"source":["... by looking a bit further, we can see that the all the results are inside a `<div class=\"s-matching-dir\">`:\n","\n","We will first get this element, and then search inside for all the `<div class=\"sg-col-inner\"...>`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-28T15:45:51.709724Z","iopub.status.idle":"2022-02-28T15:45:51.710341Z","shell.execute_reply":"2022-02-28T15:45:51.710163Z","shell.execute_reply.started":"2022-02-28T15:45:51.710137Z"},"trusted":true},"outputs":[],"source":["soup = amazon_2_soup(\"yoga mat\")\n","products = soup.find(\"div\", class_=\"s-matching-dir\").find_all(\"div\", class_=\"sg-col-inner\")\n","print(f\"Found {len(products)} products\")"]},{"cell_type":"markdown","metadata":{},"source":["We can check the code of first result:\n","\n","(there are some link to pictures: just copy-paste in a browser to verify that it is a picture of a yoga mat:\n","`https://m.media-amazon.com/images/I/71pSktIgxSL._AC_UL320_.jpg`\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-28T15:45:51.711457Z","iopub.status.idle":"2022-02-28T15:45:51.712038Z","shell.execute_reply":"2022-02-28T15:45:51.711855Z","shell.execute_reply.started":"2022-02-28T15:45:51.711835Z"},"trusted":true},"outputs":[],"source":["products[0].prettify()[:1000]"]},{"cell_type":"markdown","metadata":{},"source":["##### Parsing of Product in Amazon"]},{"cell_type":"markdown","metadata":{},"source":["The code of a product result is the following\n","\n","![Code of a product](images/amazon_uk_products.png)"]},{"cell_type":"markdown","metadata":{},"source":["You now have to extract:\n","1. The name\n","2. The price\n","\n","üí°TIP: for the price, take care of the following:\n","* Don't get several prices (we can see that it appears twice)\n","* Remove the currency with `.strip(\"¬£\")`\n","* Convert to float to store a number and not a string"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-28T15:45:51.713044Z","iopub.status.idle":"2022-02-28T15:45:51.713601Z","shell.execute_reply":"2022-02-28T15:45:51.713447Z","shell.execute_reply.started":"2022-02-28T15:45:51.713427Z"},"trusted":true},"outputs":[],"source":["prod = products[0]\n","name = ...\n","price = ...\n","# TODO: Implement to get the name and price of product (remove the ... and replace with correct code)\n","\n","print(f\"\"\"\\\n","Name: {name}\n","Price: {price}\n","\"\"\")"]},{"cell_type":"markdown","metadata":{},"source":["##### Transform into a DataFrame"]},{"cell_type":"markdown","metadata":{},"source":["Just like we did for JD, create a function to get a DataFrame for Amazon by re-using the code we just got to retrieve a product name and price (you can ignore the picture unless you feel bold enough to try).\n","\n","üõéÔ∏èIMPORTANT: the list of products might contain items without a price: you can filter by adding a condition `if prod.find(\"span\", class_=\"a-price\")` when doing a loop on all products `prod` of the list of products"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-28T15:45:51.71461Z","iopub.status.idle":"2022-02-28T15:45:51.715163Z","shell.execute_reply":"2022-02-28T15:45:51.714991Z","shell.execute_reply.started":"2022-02-28T15:45:51.714971Z"},"trusted":true},"outputs":[],"source":["# TODO: Replace ... by correct code\n","\n","def get_df_amazon(keywords):\n","    \"\"\"Get a dataframe for the results of an Amazon search\"\"\"\n","    soup = ...\n","    products = ...\n","    data_products = [\n","        {\n","            \"name\": ...,\n","            \"price\": ...,\n","        }\n","        for p in products\n","        if ...\n","    ]\n","    return pd.DataFrame(data_products)\n","\n","df = get_df_amazon(\"yoga mat\")\n","print(df.describe())\n","df"]},{"cell_type":"markdown","metadata":{},"source":["### NewEgg\n","\n","[OPTIONAL CHALLENGE]"]},{"cell_type":"markdown","metadata":{},"source":["Now that you are familiar with the basics of Web Scrapping from a merchant site, try doing the same with NewEgg:\n","\n","https://www.newegg.com/\n","\n","The purpose is to create a function `get_df_newegg` that create a DataFrame based on keywords.\n","\n","Good luck!!\n","\n","üí°#1:  For the prices, some prices are missing, so you can filter with this: `if prod.find(\"li\", class_=\"price-current\").text`\n","\n","üí°#2: The prices contain currency but also a number or offer and a strange character `\"‚Äì\"` (a sort of long hyphen): you can use the following function to extract the float value from the price as a string:\n","```python\n","def get_newegg_price(price_current):\n","    \"\"\"Process the price of a result (string) and return the string\"\"\"\n","    import re\n","    return float(re.sub(r'.*?([\\d\\.]+).*', r'\\1', price_current))\n","```\n"]},{"cell_type":"markdown","metadata":{},"source":["# THE END"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":4}
